## Probabilidades.

Las probabilidades se calculan en los rangos de 0 a 1.

- P(A) + P(~A) = 1 
    - **Ley de complemento**: Probabilidad de "A" más la diferencias siempre es 1.

- P(A y B) = P(A) * P(B)
    - **Ley multiplicativa**

- P(A o B) = P(A) + P(B) (mutuamente exclusivos)
- P(A o B) = P(A) + P(B) - P(A y B) (no exclusivos)
    - **Ley aditiva**


### Varianza
- La varianza mide que tan propagados se encuentran un conjunto de valores aleatorios de su media.
- Mientras que la media nos da una idea de donde se encuentran los valores, la varianza nos dice que tan dispersos se encuentran.
- La varianza siempre debe entenderse respecto a la media

### Desviación estándar

- La desviacón estándar es la raíz cuandrado de la varianza.
- Nos permite enteder, también, la propagación y se debe enterse siempre relacionado a al media.
- La ventaja sobre la variaza es que la desviación estándar está en las misma unidades que la media.

### Distribución normal

- Es una de las distribuciones más recurrentes en cualquier ámbito
- Se define completamente por su media y su desviación estandar
- Permite calcular intervalos de confianza con la regla empírica.

### Regla empírica

- Tambien conocida como regla 68-95-99.7(1 sigma=1,2 sigmas=1,96, 3 sigmas=3 para su uso númerico)
- Señala cuál es la dispersión de los datos en una distribución normal a uno, dos y tres sigmas(desviación estándar).
- Permite calcular probabilidades con la densidad de la distribución normal


